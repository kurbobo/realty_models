{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "resnet_image_only_regressor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6572e6eb692b4efea4a730304f49bff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f07f143daa224bbf8f4633a3d698e768",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_012610ae99b5456983e2bb8373fd98f0",
              "IPY_MODEL_b8c2f68976c249bdadb71d20fc160d1f"
            ]
          }
        },
        "f07f143daa224bbf8f4633a3d698e768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "012610ae99b5456983e2bb8373fd98f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0ace2553aacb430a9540cf1b103fe011",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1aca24a6e72434787dcaf16a9e1c6e1"
          }
        },
        "b8c2f68976c249bdadb71d20fc160d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f175eb78699a4592b5e4e938a91a484a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 953/? [07:37&lt;00:00,  2.08it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b9901bd387f45b08922c703022e0058"
          }
        },
        "0ace2553aacb430a9540cf1b103fe011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1aca24a6e72434787dcaf16a9e1c6e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f175eb78699a4592b5e4e938a91a484a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b9901bd387f45b08922c703022e0058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na4eEf06kDh3",
        "outputId": "c8eda1e7-bdc2-4aed-c837-2abe1913782e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz9AZY0Zj9Lx"
      },
      "source": [
        "https://medium.com/squad-engineering/one-class-classification-for-images-with-deep-features-69182fb4c9c5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L9mtFQWJHNc"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Qyke4fkf6o"
      },
      "source": [
        "import os\r\n",
        "import math\r\n",
        "import pandas as pd\r\n",
        "from glob import glob\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "data_path = '/content/drive/MyDrive/магистратура/realty_model/rating_system/classifier_image_only'\r\n",
        "pic_path = os.path.join(data_path, 'pic_folder')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2kOBaw0kTfe"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "from PIL import Image \r\n",
        "from torchvision import transforms, utils, datasets, models\r\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from torch.optim import lr_scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWEhrXm_kV6r",
        "outputId": "c7b27bde-e1cd-477f-fcc3-af57864a9b0f"
      },
      "source": [
        "np.random.seed(0)\r\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5265dfa870>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8nKk9sekYEH"
      },
      "source": [
        "%matplotlib inline\r\n",
        "sns.set_style('darkgrid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgV-w6drka76",
        "outputId": "db2fe61d-da1a-42d4-a321-c26ce8bb5547"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(\"We're using =>\", device)\r\n",
        "root_dir = pic_path\r\n",
        "print(\"The data lies here =>\", root_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're using => cuda\n",
            "The data lies here => /content/drive/MyDrive/магистратура/realty_model/rating_system/classifier_image_only/pic_folder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wjJFdU9ki79"
      },
      "source": [
        "import PIL\r\n",
        "image_transforms = {\r\n",
        "    \"train\": transforms.Compose([\r\n",
        "        transforms.Resize((224, 224)),\r\n",
        "        torchvision.transforms.RandomHorizontalFlip(),\r\n",
        "    torchvision.transforms.RandomRotation(20, resample=PIL.Image.BILINEAR),\r\n",
        "        transforms.ToTensor()\r\n",
        "    ]),\r\n",
        "    \"test\": transforms.Compose([\r\n",
        "        transforms.Resize((224, 224)),\r\n",
        "        transforms.ToTensor()])\r\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6BUgI545fbH"
      },
      "source": [
        "from joblib import Parallel, delayed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_VfY0hj5AB8"
      },
      "source": [
        "class rating_dataset(Dataset):\r\n",
        "    def __init__(self, dir, train=True, transform=None):\r\n",
        "        files = []\r\n",
        "        pattern   = \"*.jpeg\"\r\n",
        "        for dir,_,file_name in os.walk(dir):\r\n",
        "            files.extend(glob(os.path.join(dir,pattern)))\r\n",
        "        def get_path(x, files=files):\r\n",
        "            for i in files:\r\n",
        "                if x in i:\r\n",
        "                    return i\r\n",
        "        data = pd.read_csv(os.path.join(data_path, 'merged_data.csv'))\r\n",
        "        data = data[data['flat']!=0]\r\n",
        "        data['file_path'] = data['file_names'].apply(get_path)\r\n",
        "        data.dropna(inplace=True)\r\n",
        "        self.index, self.images = zip(*list(enumerate(data['file_path'])))\r\n",
        "        self.transform = transform\r\n",
        "        self.index = np.array(self.index)\r\n",
        "        # self.style_estim = np.array(data['style'])\r\n",
        "        self.style_estim = np.array(data['normalized_style'])\r\n",
        "        # normalized_style\r\n",
        "        self.images = Parallel(n_jobs=30)(delayed(Image.open)(i) for _, i in tqdm(enumerate(self.images)))\r\n",
        "        # self.images = [Image.open(i) for _, i in tqdm(enumerate(self.images))]\r\n",
        "        # self.images = [delayed(Image.open)(i) for _, i in tqdm(enumerate(self.images))]\r\n",
        "        \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.images)\r\n",
        "    \r\n",
        "    def __getitem__(self, item):\r\n",
        "        img = self.images[item]\r\n",
        "        if self.transform:\r\n",
        "            img = self.transform(img)\r\n",
        "        # img = cv2.imread(img)\r\n",
        "        style_estim = self.style_estim[item]\r\n",
        "        return img, style_estim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6572e6eb692b4efea4a730304f49bff2",
            "f07f143daa224bbf8f4633a3d698e768",
            "012610ae99b5456983e2bb8373fd98f0",
            "b8c2f68976c249bdadb71d20fc160d1f",
            "0ace2553aacb430a9540cf1b103fe011",
            "d1aca24a6e72434787dcaf16a9e1c6e1",
            "f175eb78699a4592b5e4e938a91a484a",
            "9b9901bd387f45b08922c703022e0058"
          ]
        },
        "id": "P_2LPX77kopR",
        "outputId": "dc836250-8d7e-4f07-c0d0-5d0395c92474"
      },
      "source": [
        "flat_dataset = rating_dataset(pic_path, transform=image_transforms['train'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6572e6eb692b4efea4a730304f49bff2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS5LSHOvFsyX",
        "outputId": "65cd8454-4818-4ec0-bb6d-85c18f0b8731"
      },
      "source": [
        "len(flat_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "953"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7nxB4OczQzu"
      },
      "source": [
        "data = pd.read_csv(os.path.join(data_path, 'merged_data.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rdZqqYVW2xv6",
        "outputId": "106ef8f2-1abc-4292-e123-e9581e0df601"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_names</th>\n",
              "      <th>flat</th>\n",
              "      <th>restoration</th>\n",
              "      <th>style</th>\n",
              "      <th>labeler_id</th>\n",
              "      <th>normalized_style</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-100918699400681824.jpeg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-3.225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-100918699400681904.jpeg</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-100918699417093520.jpeg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-3.225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-100918699417093744.jpeg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-3.225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-103646700382705216.jpeg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-3.225</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 file_names  flat  ...  labeler_id  normalized_style\n",
              "0  -100918699400681824.jpeg   0.0  ...           0            -3.225\n",
              "1  -100918699400681904.jpeg   1.0  ...           0             3.775\n",
              "2  -100918699417093520.jpeg   0.0  ...           0            -3.225\n",
              "3  -100918699417093744.jpeg   0.0  ...           0            -3.225\n",
              "4  -103646700382705216.jpeg   0.0  ...           0            -3.225\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc8TruSM3eG9"
      },
      "source": [
        "data = data[data['flat']!=0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NCvT3KzGwJZ"
      },
      "source": [
        "data['style'] = data['style'].apply(lambda x: str(int(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJJjo315HjIq",
        "outputId": "9a04c996-54f4-4a47-f03b-dee6245d3526"
      },
      "source": [
        "data.groupby('style')['file_names'].count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "style\n",
              "0     157\n",
              "1      18\n",
              "10     94\n",
              "2      24\n",
              "3      47\n",
              "4      85\n",
              "5     113\n",
              "6     110\n",
              "7     156\n",
              "8     107\n",
              "9      46\n",
              "Name: file_names, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M4s0YTFks7I"
      },
      "source": [
        "flat_dataset_size = len(flat_dataset)\r\n",
        "flat_dataset_indices = list(range(flat_dataset_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsGk8VWGkwpL"
      },
      "source": [
        "np.random.shuffle(flat_dataset_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2qxoFgxkyk8"
      },
      "source": [
        "val_split_index = int(np.floor(0.2 * flat_dataset_size))\r\n",
        "test_split_index = int(np.floor(0.4 * flat_dataset_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsdHH8eUk0i0"
      },
      "source": [
        "train_idx, test_idx, val_idx = flat_dataset_indices[test_split_index:], flat_dataset_indices[val_split_index:test_split_index], flat_dataset_indices[:val_split_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtBf3U_eHUcE",
        "outputId": "f713c8ab-819a-4ac1-d4ff-641650440c8f"
      },
      "source": [
        "len(train_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "572"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7pSiPLPHWpk",
        "outputId": "60cd3f1c-0fb3-41a7-eb55-1dd034479987"
      },
      "source": [
        "len(test_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "191"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMOYGZt6HZtU",
        "outputId": "c6d7ce8a-b94a-42a4-9cb2-a69f07992833"
      },
      "source": [
        "len(val_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "190"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWsqYOltSYF_"
      },
      "source": [
        "dataset_sizes = {}\r\n",
        "dataset_sizes['train'] = len(train_idx)\r\n",
        "dataset_sizes['val'] = len(val_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4jqdrtnlibN",
        "outputId": "d8af5613-e542-46d1-a321-e6a9964baded"
      },
      "source": [
        "len(flat_dataset_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "953"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd13DfZqk2Y-"
      },
      "source": [
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\r\n",
        "valid_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\r\n",
        "test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRU1Gdr7rsso"
      },
      "source": [
        "train_loader = DataLoader(dataset=flat_dataset, shuffle=False, batch_size=64, sampler=train_sampler)\r\n",
        "val_loader = DataLoader(dataset=flat_dataset, shuffle=False, batch_size=32, sampler=valid_sampler)\r\n",
        "test_loader = DataLoader(dataset=flat_dataset, shuffle=False, batch_size=32, sampler=test_sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZEmGibUQe6D"
      },
      "source": [
        "dataloaders = {}\r\n",
        "dataloaders['train'] = train_loader\r\n",
        "dataloaders['val'] = val_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEaPweMKryYf",
        "outputId": "ae24aec9-f8d6-4781-ad0a-9665c8fa9389"
      },
      "source": [
        "model = models.resnet50(pretrained=True,)\r\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR\r\n",
        "print(model)\r\n",
        "model.fc = nn.Sequential(nn.Linear(2048, 512),\r\n",
        "                                 nn.ReLU(),\r\n",
        "                                 nn.Dropout(0.2),\r\n",
        "                                 nn.Linear(512, 1))\r\n",
        "criterion = nn.MSELoss()\r\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.01, weight_decay=1e-2)\r\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\r\n",
        "# swa_scheduler = SWALR(optimizer, swa_lr=0.05)\r\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WmMi9HHvNlV"
      },
      "source": [
        "import time\r\n",
        "import copy\r\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=40):\r\n",
        "    since = time.time()\r\n",
        "    train_loss = []\r\n",
        "    val_loss = []\r\n",
        "\r\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "    best_loss = np.inf\r\n",
        "\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\r\n",
        "        print('-' * 10)\r\n",
        "\r\n",
        "        # Each epoch has a training and validation phase\r\n",
        "        for phase in ['train', 'val']:\r\n",
        "            if phase == 'train':\r\n",
        "                model.train()  # Set model to training mode\r\n",
        "            else:\r\n",
        "                model.eval()   # Set model to evaluate mode\r\n",
        "\r\n",
        "            running_loss = 0.0\r\n",
        "            running_corrects = 0\r\n",
        "\r\n",
        "            # Iterate over data.\r\n",
        "            for inputs, labels in dataloaders[phase]:\r\n",
        "                inputs = inputs.to(device)\r\n",
        "                labels = labels.float().to(device)\r\n",
        "\r\n",
        "                # zero the parameter gradients\r\n",
        "                optimizer.zero_grad()\r\n",
        "\r\n",
        "                # forward\r\n",
        "                # track history if only in train\r\n",
        "                with torch.set_grad_enabled(phase == 'train'):\r\n",
        "                    outputs = model(inputs).float()\r\n",
        "                    loss = criterion(outputs, labels.unsqueeze(1))\r\n",
        "\r\n",
        "                    # backward + optimize only if in training phase\r\n",
        "                    if phase == 'train':\r\n",
        "                        loss.backward()\r\n",
        "                        optimizer.step()\r\n",
        "\r\n",
        "                # statistics\r\n",
        "                running_loss += loss.item() * inputs.size(0)\r\n",
        "                # running_corrects += torch.sum(preds == labels.data)\r\n",
        "            if phase == 'train':\r\n",
        "                scheduler.step()\r\n",
        "\r\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\r\n",
        "            # epoch_acc = running_corrects.double() / dataset_sizes[phase]\r\n",
        "            if phase=='train':\r\n",
        "                train_loss.append(epoch_loss)\r\n",
        "            else:\r\n",
        "                val_loss.append(epoch_loss)\r\n",
        "            print('{} Loss: {:.4f} '.format(\r\n",
        "                phase, epoch_loss))\r\n",
        "\r\n",
        "            # deep copy the model\r\n",
        "            if phase == 'val' and epoch_loss < best_loss:\r\n",
        "                best_loss = epoch_loss\r\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "\r\n",
        "        print()\r\n",
        "\r\n",
        "    time_elapsed = time.time() - since\r\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\r\n",
        "        time_elapsed // 60, time_elapsed % 60))\r\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\r\n",
        "\r\n",
        "    # load best model weights\r\n",
        "    print('hello')\r\n",
        "    model.load_state_dict(best_model_wts)\r\n",
        "    print('buy')\r\n",
        "    return model, train_loss, val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BENiIEbyP_re",
        "outputId": "3f869163-6dea-4097-e0a5-b4155f92026d"
      },
      "source": [
        "model_conv, train_loss, val_loss = train_model(model, criterion, optimizer,\r\n",
        "                         swa_scheduler, num_epochs=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/39\n",
            "----------\n",
            "train Loss: 490.3893 \n",
            "val Loss: 85.6195 \n",
            "\n",
            "Epoch 1/39\n",
            "----------\n",
            "train Loss: 36.8817 \n",
            "val Loss: 13.5762 \n",
            "\n",
            "Epoch 2/39\n",
            "----------\n",
            "train Loss: 13.0194 \n",
            "val Loss: 6.7991 \n",
            "\n",
            "Epoch 3/39\n",
            "----------\n",
            "train Loss: 8.1783 \n",
            "val Loss: 7.1017 \n",
            "\n",
            "Epoch 4/39\n",
            "----------\n",
            "train Loss: 6.7836 \n",
            "val Loss: 4.9152 \n",
            "\n",
            "Epoch 5/39\n",
            "----------\n",
            "train Loss: 5.1916 \n",
            "val Loss: 3.5365 \n",
            "\n",
            "Epoch 6/39\n",
            "----------\n",
            "train Loss: 4.6521 \n",
            "val Loss: 5.0647 \n",
            "\n",
            "Epoch 7/39\n",
            "----------\n",
            "train Loss: 4.8643 \n",
            "val Loss: 4.6553 \n",
            "\n",
            "Epoch 8/39\n",
            "----------\n",
            "train Loss: 4.8092 \n",
            "val Loss: 3.5941 \n",
            "\n",
            "Epoch 9/39\n",
            "----------\n",
            "train Loss: 4.4528 \n",
            "val Loss: 4.3535 \n",
            "\n",
            "Epoch 10/39\n",
            "----------\n",
            "train Loss: 4.4034 \n",
            "val Loss: 5.2680 \n",
            "\n",
            "Epoch 11/39\n",
            "----------\n",
            "train Loss: 4.3519 \n",
            "val Loss: 3.0930 \n",
            "\n",
            "Epoch 12/39\n",
            "----------\n",
            "train Loss: 4.3930 \n",
            "val Loss: 3.6537 \n",
            "\n",
            "Epoch 13/39\n",
            "----------\n",
            "train Loss: 4.3055 \n",
            "val Loss: 3.1984 \n",
            "\n",
            "Epoch 14/39\n",
            "----------\n",
            "train Loss: 4.1600 \n",
            "val Loss: 3.4336 \n",
            "\n",
            "Epoch 15/39\n",
            "----------\n",
            "train Loss: 3.8814 \n",
            "val Loss: 3.4513 \n",
            "\n",
            "Epoch 16/39\n",
            "----------\n",
            "train Loss: 3.4493 \n",
            "val Loss: 4.0189 \n",
            "\n",
            "Epoch 17/39\n",
            "----------\n",
            "train Loss: 4.1965 \n",
            "val Loss: 4.1213 \n",
            "\n",
            "Epoch 18/39\n",
            "----------\n",
            "train Loss: 3.5798 \n",
            "val Loss: 3.5350 \n",
            "\n",
            "Epoch 19/39\n",
            "----------\n",
            "train Loss: 3.7130 \n",
            "val Loss: 4.1452 \n",
            "\n",
            "Epoch 20/39\n",
            "----------\n",
            "train Loss: 3.8337 \n",
            "val Loss: 3.2782 \n",
            "\n",
            "Epoch 21/39\n",
            "----------\n",
            "train Loss: 3.3917 \n",
            "val Loss: 3.3202 \n",
            "\n",
            "Epoch 22/39\n",
            "----------\n",
            "train Loss: 3.6863 \n",
            "val Loss: 3.6225 \n",
            "\n",
            "Epoch 23/39\n",
            "----------\n",
            "train Loss: 3.6235 \n",
            "val Loss: 3.6347 \n",
            "\n",
            "Epoch 24/39\n",
            "----------\n",
            "train Loss: 3.7219 \n",
            "val Loss: 3.8772 \n",
            "\n",
            "Epoch 25/39\n",
            "----------\n",
            "train Loss: 3.4452 \n",
            "val Loss: 4.9017 \n",
            "\n",
            "Epoch 26/39\n",
            "----------\n",
            "train Loss: 5.8750 \n",
            "val Loss: 6.7633 \n",
            "\n",
            "Epoch 27/39\n",
            "----------\n",
            "train Loss: 5.7672 \n",
            "val Loss: 8.3847 \n",
            "\n",
            "Epoch 28/39\n",
            "----------\n",
            "train Loss: 5.2420 \n",
            "val Loss: 4.3630 \n",
            "\n",
            "Epoch 29/39\n",
            "----------\n",
            "train Loss: 3.8123 \n",
            "val Loss: 3.1563 \n",
            "\n",
            "Epoch 30/39\n",
            "----------\n",
            "train Loss: 3.5164 \n",
            "val Loss: 3.4432 \n",
            "\n",
            "Epoch 31/39\n",
            "----------\n",
            "train Loss: 3.4653 \n",
            "val Loss: 3.4745 \n",
            "\n",
            "Epoch 32/39\n",
            "----------\n",
            "train Loss: 3.5153 \n",
            "val Loss: 2.9677 \n",
            "\n",
            "Epoch 33/39\n",
            "----------\n",
            "train Loss: 3.3157 \n",
            "val Loss: 4.1781 \n",
            "\n",
            "Epoch 34/39\n",
            "----------\n",
            "train Loss: 4.4445 \n",
            "val Loss: 3.4927 \n",
            "\n",
            "Epoch 35/39\n",
            "----------\n",
            "train Loss: 3.5955 \n",
            "val Loss: 3.9247 \n",
            "\n",
            "Epoch 36/39\n",
            "----------\n",
            "train Loss: 4.5994 \n",
            "val Loss: 3.1109 \n",
            "\n",
            "Epoch 37/39\n",
            "----------\n",
            "train Loss: 3.6490 \n",
            "val Loss: 3.3677 \n",
            "\n",
            "Epoch 38/39\n",
            "----------\n",
            "train Loss: 4.5372 \n",
            "val Loss: 3.7800 \n",
            "\n",
            "Epoch 39/39\n",
            "----------\n",
            "train Loss: 3.4630 \n",
            "val Loss: 7.0848 \n",
            "\n",
            "Training complete in 6m 49s\n",
            "Best val loss: 2.967651\n",
            "hello\n",
            "buy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJAnRkb76p0z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c8b4c783-0bff-4393-f4ae-5dd339b2bf31"
      },
      "source": [
        "plt.plot(train_loss, label='train_loss')\r\n",
        "plt.plot(val_loss, label='val_loss')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlsgKl4qJMQw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "260c8823-c639-4161-94f6-6a49c8f82d8e"
      },
      "source": [
        "import plotly.express as px\r\n",
        "a =1\r\n",
        "b = -1\r\n",
        "fig = px.line(x=list(range(40)[a:b]), y=train_loss[a:b], labels={'y':'losses', 'x':'epochs'})\r\n",
        "fig.add_scatter(x=list(range(40)[a:b]), y=val_loss[a:b], mode='lines')\r\n",
        "# fig = px.line(x=list(range(40)), y=val_loss)\r\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"6e3e2df2-94c8-48b5-8f7c-edcb5b3b96c4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"6e3e2df2-94c8-48b5-8f7c-edcb5b3b96c4\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '6e3e2df2-94c8-48b5-8f7c-edcb5b3b96c4',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"epochs=%{x}<br>losses=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38], \"xaxis\": \"x\", \"y\": [36.88165788717203, 13.019354580165622, 8.178340641768662, 6.783577112051157, 5.191591166116141, 4.652077464790611, 4.864327784184809, 4.809245169579566, 4.452809920677772, 4.4033776263257005, 4.351879763436484, 4.392979495175235, 4.305452793628186, 4.159975558727771, 3.8814294121482154, 3.449302056452611, 4.196464466881919, 3.57980535747288, 3.712950918224308, 3.8337114540847033, 3.391668449748646, 3.6862562419651272, 3.6235384941101074, 3.721854259917786, 3.4451808245865614, 5.874990483263989, 5.767243785458011, 5.241985867907117, 3.812312159504924, 3.5163507244803687, 3.465276799835525, 3.515283334505308, 3.315664204684171, 4.4445478466007255, 3.5955373190499684, 4.5994046117875955, 3.64895114031705, 4.537215988119166], \"yaxis\": \"y\"}, {\"mode\": \"lines\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38], \"y\": [13.576194933841103, 6.799068636643259, 7.101749460320724, 4.915239223680998, 3.5365027051222953, 5.064696999600059, 4.655337193137721, 3.5940984173824915, 4.353458258980199, 5.268025573931243, 3.0930124935350922, 3.6536726775922275, 3.198375970438907, 3.433555939323024, 3.4512746509752774, 4.018938330600136, 4.121307834826018, 3.534970840654875, 4.145228581679495, 3.278239049409565, 3.320211962649697, 3.6225044049714743, 3.6347320054706773, 3.8771578311920165, 4.9016578046899095, 6.763338259646767, 8.384724125109221, 4.362963872206839, 3.156271952076962, 3.443166110390111, 3.4745472732343172, 2.9676507422798557, 4.1780976295471195, 3.4926844797636334, 3.924660476885344, 3.1109365061709755, 3.367721384450009, 3.779993498952765]}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"epochs\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"losses\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6e3e2df2-94c8-48b5-8f7c-edcb5b3b96c4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmenzfz_W8dE"
      },
      "source": [
        "from torch.autograd import Variable\r\n",
        "def predict_image(image, model):\r\n",
        "    image_tensor = image_transforms[\"test\"](image)\r\n",
        "    # image_tensor = image_tensor.unsqueeze_(0)\r\n",
        "    input = Variable(image_tensor)\r\n",
        "    input = input.to(device)\r\n",
        "    output = model(input)\r\n",
        "    index = output.data.cpu().numpy().argmax()\r\n",
        "    return index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTF-qaUEJ_1P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPT9T7AAYkCl"
      },
      "source": [
        "def get_random_images(num=None):\r\n",
        "    data = flat_dataset_test\r\n",
        "    classes = data.classes\r\n",
        "    indices = list(range(len(data)))\r\n",
        "    np.random.shuffle(indices)\r\n",
        "    if num is None:\r\n",
        "        idx = indices[:]\r\n",
        "        num = len(indices)\r\n",
        "    else:\r\n",
        "        idx = indices[:num]\r\n",
        "    from torch.utils.data.sampler import SubsetRandomSampler\r\n",
        "    sampler = SubsetRandomSampler(idx)\r\n",
        "    loader = torch.utils.data.DataLoader(data, \r\n",
        "                   sampler=sampler, batch_size=num)\r\n",
        "    dataiter = iter(loader)\r\n",
        "    images, labels = dataiter.next()\r\n",
        "    return images, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijkaWrR3YHQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed06587-56ac-43c9-d8ff-46d69743469c"
      },
      "source": [
        "criterion = nn.L1Loss()\r\n",
        "losses = []\r\n",
        "for inputs, labels in test_loader:\r\n",
        "    inputs = inputs.to(device)\r\n",
        "    labels = labels.float().to(device)\r\n",
        "    with torch.set_grad_enabled(False):\r\n",
        "        outputs = model(inputs).float()\r\n",
        "        loss = criterion(outputs, labels.unsqueeze(1))\r\n",
        "        losses.append(loss.cpu().numpy())\r\n",
        "print(sum(losses)/len(losses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5425451397895813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wsKyv9YVI_W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBuq-nfmckp0"
      },
      "source": [
        "# os.path.join(data_path, 'x_train.npy')\r\n",
        "torch.save(model_conv.state_dict(), os.path.join(data_path, 'resnet50_pretrained_image_regression.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}